{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1691f85-ab42-4535-8b20-8b6e2409e40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in e:\\anaconda\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: httpx>=0.27 in e:\\anaconda\\lib\\site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in e:\\anaconda\\lib\\site-packages (from ollama) (2.12.0)\n",
      "Requirement already satisfied: anyio in e:\\anaconda\\lib\\site-packages (from httpx>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in e:\\anaconda\\lib\\site-packages (from httpx>=0.27->ollama) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\anaconda\\lib\\site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\anaconda\\lib\\site-packages (from httpx>=0.27->ollama) (2.10)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\anaconda\\lib\\site-packages (from pydantic>=2.9->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in e:\\anaconda\\lib\\site-packages (from pydantic>=2.9->ollama) (2.41.1)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in e:\\anaconda\\lib\\site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in e:\\anaconda\\lib\\site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\anaconda\\lib\\site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1c38e-d684-4152-a201-dc64a2861512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "topic = \"a new AI-powered coffee mug that keeps coffee at the perfect temperature\"\n",
    "\n",
    "# --- Chain Step 1: The Creative (Draft 1) ---\n",
    "print(\"[Creative] Generating initial slogans...\")\n",
    "creative_prompt = f\"Generate 5 catchy marketing slogans for: {topic}\"\n",
    "response_v1 = ollama.chat(\n",
    "    model='llama3.2:1b',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a creative advertising executive.'},\n",
    "        {'role': 'user', 'content': creative_prompt}\n",
    "    ]\n",
    ")\n",
    "draft_v1 = response_v1['message']['content']\n",
    "print(f\"--- DRAFT 1 ---\\n{draft_v1}\\n-----------------\")\n",
    "\n",
    "# --- Chain Step 2: The Critic ---\n",
    "# We feed Draft 1 to the Critic model.\n",
    "print(\"[Critic] Critiquing the first draft...\")\n",
    "critic_prompt = f\"\"\"\n",
    "You are a harsh but constructive critic. Review these slogans and provide\n",
    "3 bullet points on how to make them more \"punchy\" and \"memorable\".\n",
    "\n",
    "Slogans:\n",
    "{draft_v1}\n",
    "\"\"\"\n",
    "critic_response = ollama.chat(\n",
    "    model='qwen3:8b',  # Using a different model for a \"second opinion\"\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a demanding brand strategist.'},\n",
    "        {'role': 'user', 'content': critic_prompt}\n",
    "    ]\n",
    ")\n",
    "critique = critic_response['message']['content']\n",
    "print(f\"--- CRITIQUE ---\\n{critique}\\n-----------------\")\n",
    "\n",
    "\n",
    "# --- Chain Step 3: The Creative (Draft 2) ---\n",
    "# We feed BOTH the original prompt AND the critique back to the Creative.\n",
    "print(\"[Creative] Generating revised slogans based on critique...\")\n",
    "revision_prompt = f\"\"\"\n",
    "Your first draft of slogans was:\n",
    "{draft_v1}\n",
    "\n",
    "A critic provided this feedback:\n",
    "{critique}\n",
    "\n",
    "Now, please provide a new list of 5 slogans that addresses this feedback directly.\n",
    "\"\"\"\n",
    "response_v2 = ollama.chat(\n",
    "    model='llama3.2:1b', # Back to the creative model\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a creative advertising executive.'},\n",
    "        {'role': 'user', 'content': revision_prompt}\n",
    "    ]\n",
    ")\n",
    "draft_v2 = response_v2['message']['content']\n",
    "\n",
    "# --- Final Output ---\n",
    "print(\"\\n\\n--- FINAL REVISED SLOGANS ---\")\n",
    "print(draft_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ecf23-412e-4b49-a44b-105340739403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b478a0-09ad-46a1-a563-b7c818c5ae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
